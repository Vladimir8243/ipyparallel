{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Train a GPT-2 Text-Generating Model w/ GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vladimir8243/ipyparallel/blob/master/Copy_of_Train_a_GPT_2_Text_Generating_Model_w_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: August 28th, 2019*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE",
        "colab_type": "text"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab_type": "code",
        "outputId": "3b16fafd-669b-44bf-e1aa-9cc10c07c05e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Sep  7 19:41:18 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QstCaKJERW1x",
        "colab_type": "code",
        "outputId": "049a0a62-dfe6-4034-cd82-10c47a9609ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "import requests\n",
        "full_text = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt').text\n",
        "text = full_text.split('THE SONNETS')[1]\n",
        "\n",
        "\n",
        "print(text[:100])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "by William Shakespeare\n",
            "\n",
            "\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  Th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "outputId": "c2ce377e-96c3-4350-ea42-542d23e3b314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 290Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 109Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 595Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:02, 231Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 375Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 170Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 168Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab_type": "code",
        "outputId": "8d0234b9-a68f-4775-f572-91b56f51fdb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"shakespeare.txt\"\n",
        "#file_name = text\n",
        "#text_file = open(file_name, 'w+')\n",
        "#text_file.write(text)\n",
        "#text_file.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE",
        "colab_type": "text"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK4rGTGbSyDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e00bc567-3bb4-4cb2-c45d-2b6dd340320c"
      },
      "source": [
        "file_name[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'shakespear'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohI3cdLcO2Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_HsfXQNUWN5",
        "colab_type": "code",
        "outputId": "d263e4c9-362f-4cdf-c353-355d82d3bce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCvCi1DBOtHT",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "6d8d80ca-01d7-4134-f0f4-e4eb5cbc39ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:07<00:00,  7.25s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 1847425 tokens\n",
            "Training...\n",
            "[10 | 28.44] loss=3.04 avg=3.04\n",
            "[20 | 50.78] loss=2.99 avg=3.02\n",
            "[30 | 73.91] loss=2.80 avg=2.95\n",
            "[40 | 98.21] loss=2.89 avg=2.93\n",
            "[50 | 122.73] loss=3.32 avg=3.01\n",
            "[60 | 146.48] loss=2.57 avg=2.93\n",
            "[70 | 170.37] loss=2.95 avg=2.94\n",
            "[80 | 194.67] loss=2.68 avg=2.90\n",
            "[90 | 218.98] loss=2.79 avg=2.89\n",
            "[100 | 243.22] loss=2.73 avg=2.87\n",
            "[110 | 267.39] loss=2.73 avg=2.86\n",
            "[120 | 291.47] loss=2.77 avg=2.85\n",
            "[130 | 315.61] loss=2.68 avg=2.84\n",
            "[140 | 339.81] loss=2.66 avg=2.82\n",
            "[150 | 364.08] loss=2.66 avg=2.81\n",
            "[160 | 388.37] loss=2.97 avg=2.82\n",
            "[170 | 412.62] loss=3.03 avg=2.84\n",
            "[180 | 436.80] loss=2.94 avg=2.84\n",
            "[190 | 461.00] loss=2.32 avg=2.81\n",
            "[200 | 485.25] loss=2.40 avg=2.79\n",
            "======== SAMPLE 1 ========\n",
            " thee of him\n",
            "     How you, if he be such, have no more in him.\n",
            "     You are a kind of fool, sir, which is a kind of mirth and a kind of\n",
            "     foolishness; and so, unless you be such, you are fool enough of 'em.\n",
            "     There's that which I should not say, which I cannot say,  \n",
            "     Or have not, though the rest should, but I am not a fool\n",
            "     For that you are a fool. But let me have this one with a kiss;\n",
            "     And I'll make it the only one that doth dost have a kiss.\n",
            "     It will be a one that is of a good description.\n",
            "  RICHARD. I hope, sir, I'll have the other. If a woman be so kind, then she's a good\n",
            "     woman. If I am a man, then I am a villain; and, even so, I cannot make\n",
            "     an otherwise, if I were a gentleman, if I were a gentleman.\n",
            "  HELENA. I thank you all, sir; if I were a gentleman it is for my\n",
            "     self, and he that would give it willingly, I'd give away his soul.\n",
            "  RICHARD. My lords, a gentleman is a gentleman; if he give way, I'll give way.\n",
            "  HELENA. Sirrah, a gentleman is a gentleman if I have some thing to change it.  \n",
            "    And a gentleman, when you show yourself a friend and, after the\n",
            "     business, will give money to your lordship, is a gentleman enough, and\n",
            "     a gentleman enough is as well as a gentleman.\n",
            "  SIR TOBY. I thank you, sir, for being as true in your tongue your lordship is.\n",
            "  HELENA. I am not a gentleman. I think my lordship knows a gentleman.\n",
            "  SIR TOBY. I am a lout. I thought I had it that you were a man-\n",
            "  HELENA. I am not a man. I would be if you were a gentleman.\n",
            "  SIR TOBY. I am a lout.  \n",
            "  HELENA. I am not a gentleman. I think I have it that you are a man.\n",
            "  SIR TOBY. I am not a man. 'Tis not so.\n",
            "  HELENA. I can tell you that.\n",
            "  SIR TOBY. I have no more in me.\n",
            "  HELENA. I would say he is a man. I have seen he\n",
            "     is more of a gentleman at times like one that is a lout.\n",
            "  SIR TOBY. This is a very strange man, I see.\n",
            "  HELENA. Ay, methinks I.\n",
            "  SIR TOBY. You are a man, sir.\n",
            "  HELENA. Nay, sir, but methinks I am a man more than a gentleman;\n",
            "    but, sir, is this the case?\n",
            "  SIR TOBY. I'll do a good deal.\n",
            "  HELENA. I will do a good deal.\n",
            "  SIR TOBY. Ay, sir.\n",
            "  HELENA. Ay, sir.\n",
            "  SIR TOBY. I would not.  \n",
            "  HELENA. I will say my lordship is a gentleman.\n",
            "  SIR TOBY. I am a gentleman; my lordship is no less worthy of that.\n",
            "  HELENA. No more worthy of that; for if I be a man, and I be a man\n",
            "     then I am a gentleman.\n",
            "  SIR TOBY. By heaven, a gentleman.\n",
            "  HELENA. That's not the point.\n",
            "  SIR TOBY. You shall tell me that, or I'll tell you how.\n",
            "  HELENA. What is it that I am that you say to me?\n",
            "  SIR TOBY. I am a gentleman.  \n",
            "  HELENA. My lord?  [Puts up the letter of his seal] You shall learn me this, and make me master.  \n",
            "  SIR TOBY. My lordship?  \n",
            "  HELENA. Sirrah, sir,\n",
            "  SIR TOBY. Sirrah, sir, you shall learn me this.\n",
            "  HELENA. I have a man's name, sir.\n",
            "  SIR TOBY. I am a gentleman.\n",
            "  HELENA. I am a gentleman;\n",
            "    And Sir Richard of the King's army is a gentleman.\n",
            "  SIR TOBY. And Sir Richard of the Duke of York.\n",
            "\n",
            "[210 | 521.38] loss=2.52 avg=2.77\n",
            "[220 | 545.58] loss=2.71 avg=2.77\n",
            "[230 | 569.79] loss=2.48 avg=2.76\n",
            "[240 | 594.00] loss=2.98 avg=2.77\n",
            "[250 | 618.21] loss=2.64 avg=2.76\n",
            "[260 | 642.41] loss=2.39 avg=2.75\n",
            "[270 | 666.62] loss=2.66 avg=2.74\n",
            "[280 | 690.83] loss=2.63 avg=2.74\n",
            "[290 | 715.13] loss=2.51 avg=2.73\n",
            "[300 | 739.46] loss=2.76 avg=2.73\n",
            "[310 | 763.79] loss=2.53 avg=2.72\n",
            "[320 | 788.09] loss=2.41 avg=2.71\n",
            "[330 | 812.40] loss=2.70 avg=2.71\n",
            "[340 | 836.68] loss=2.52 avg=2.70\n",
            "[350 | 860.96] loss=2.73 avg=2.70\n",
            "[360 | 885.23] loss=2.58 avg=2.70\n",
            "[370 | 909.49] loss=2.60 avg=2.70\n",
            "[380 | 933.76] loss=2.64 avg=2.70\n",
            "[390 | 957.98] loss=2.62 avg=2.69\n",
            "[400 | 982.21] loss=2.61 avg=2.69\n",
            "======== SAMPLE 1 ========\n",
            " So.  \n",
            "  BRUTUS. How then is that our way made?\n",
            "    Who came this way to the city?\n",
            "    When I was born, I had no fear.\n",
            "    Was not the Roman fleet to thee made\n",
            "    Since so fair her beauty should be so admired?\n",
            "    Didst thou not write a sconce, and say\n",
            "    'The Roman fleet was in Athens and Rome'?\n",
            "    No, I say, I thought thou wouldst see the end.\n",
            "    Then let me read it.\n",
            "  BRUTUS. I'll read it presently.\n",
            "  LAVINIA. It is a good word.\n",
            "  BASSIANUS. And in truth, it is.\n",
            "  CAESAR. So am I. You see, for a man\n",
            "    of the nature of our town, that I think him good;\n",
            "    We'll make a good business of him.\n",
            "  BASSIANUS. You'll be proud of it.\n",
            "    He is our friend in Athens and Rome,\n",
            "    But he is by some false account a fool.\n",
            "    To call him a man of Athens\n",
            "    Though the people shall not name him a villain is but an\n",
            "    counterfeit.\n",
            "  LAVINIA. Yes, he is a villain in our town; he is\n",
            "    an ass.\n",
            "  BASSIANUS. Is here Caesar's son?\n",
            "  CAESAR. And for the King?\n",
            "  BASSIANUS. Caesar his king?\n",
            "  CAESAR. And yet for Caesar's brother, Caesar his son.\n",
            "  BRUTUS. That is but a false account, if Caesar be so.\n",
            "    He is a villain; he was in the state of Pompey\n",
            "    Before he comes to Athens.\n",
            "  BASSIANUS. He is the Caesar's boy.\n",
            "  CAESAR. That's the false account of Caesar.\n",
            "    His father was a king's brother, if he remember the\n",
            "    name, an ass if he remember the villain; and Caesar's child\n",
            "    being the prince's uncle, Caesar's daughter, would be much\n",
            "    proud of Caesar's father than is Caesar's mother.\n",
            "    My noble friend, Caesar, howsoever may I make\n",
            "    your friends proud.\n",
            "  BASSIANUS. Go to your ways, Caesar; get at Caesar's house\n",
            "    and kill our friend, so that we may take our revenge.\n",
            "    Now let me tell you all I may, you shall\n",
            "    be not a villain in Athens.\n",
            "  BRUTUS. How now, villain! how now! Why is a noble\n",
            "    man?\n",
            "  BASSIANUS. That's well known.\n",
            "  PROSPERO. Why did Caesar kill Romeo?\n",
            "  BASSIANUS. [Aside] Then to his shame were you.\n",
            "    But who was that?\n",
            "  PROSPERO. O my lord, let me tell thee this:\n",
            "    The Duke of Gloucestershire, he was but a\n",
            "    nobleman, that never did kill a man.\n",
            "  BASSIANUS. Why, then there was you, I say. But that man\n",
            "    whom in your time I had told how it went, did\n",
            "    kill none but himself.\n",
            "  PROSPERO. [Aside] I do not think that your friends can do him\n",
            "    wrong.\n",
            "  BASSIANUS. I am glad to hear\n",
            "  PROSPERO. I must say one word.\n",
            "  BASSIANUS. You shall remember, my lord, to whom I said the\n",
            "    Duke of Gloucestershire, when you heard of him,\n",
            "    he did not do you wrong. This man, who should do you wrong\n",
            "    much, I think he might be most villainy. This gentleman\n",
            "    which you heard of\n",
            "    do not have so many enemies, but many friends.\n",
            "    Wherefore, Caesar?\n",
            "  BRUTUS. I have often heard you say he has not many enemies,\n",
            "    because you have not seen them. I am sorry.\n",
            "  BASSIANUS. Ay, Caesar, I confess your fault.\n",
            "    But have you ever read your wrongs, have you ever\n",
            "    had a letter from your father, that ever did write\n",
            "    you wrong. I shall not be a traitor to you.\n",
            "  BRUTUS. By my faith, sir, not by your fault.\n",
            "\n",
            "\n",
            "[410 | 1017.24] loss=2.31 avg=2.68\n",
            "[420 | 1041.41] loss=2.45 avg=2.67\n",
            "[430 | 1065.64] loss=2.63 avg=2.67\n",
            "[440 | 1089.93] loss=2.42 avg=2.66\n",
            "[450 | 1114.27] loss=2.83 avg=2.67\n",
            "[460 | 1138.62] loss=2.61 avg=2.67\n",
            "[470 | 1163.01] loss=2.76 avg=2.67\n",
            "[480 | 1187.44] loss=2.39 avg=2.66\n",
            "[490 | 1211.79] loss=2.48 avg=2.66\n",
            "[500 | 1236.09] loss=2.41 avg=2.65\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 1262.94] loss=2.57 avg=2.65\n",
            "[520 | 1287.35] loss=2.22 avg=2.64\n",
            "[530 | 1311.67] loss=2.32 avg=2.63\n",
            "[540 | 1335.81] loss=2.64 avg=2.63\n",
            "[550 | 1359.96] loss=2.43 avg=2.63\n",
            "[560 | 1384.20] loss=2.35 avg=2.62\n",
            "[570 | 1408.47] loss=2.59 avg=2.62\n",
            "[580 | 1432.75] loss=2.57 avg=2.62\n",
            "[590 | 1457.11] loss=2.49 avg=2.62\n",
            "[600 | 1481.40] loss=2.18 avg=2.61\n",
            "======== SAMPLE 1 ========\n",
            "            Exit\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCENE VI.\n",
            "Trammont. The garden\n",
            "\n",
            "Enter ROSALIND and STEPHEN\n",
            "\n",
            "  STEPHEN. And who came but this hour? How came\n",
            "    This gallant young man hither?\n",
            "\n",
            "    Enter two PISANIO and MENENIUS\n",
            "\n",
            "  STEPHEN. Come not hither, and let him speak what\n",
            "    He will, till he meet me at a feast of friends of his.\n",
            "  MENENIUS. Nay, come not hither, and let him speak what pleases him.\n",
            "  STEPHEN.                           [They stand aside]\n",
            "  MENENIUS. Why, are you all here? Do you hear, gentlemen?\n",
            "  THURIO. I have more music than I ever saw you.\n",
            "  MENENIUS. Why, a hundred trumpets, a thousand thousand, and I\n",
            "    can fit it all through. I think it is the greatest.\n",
            "  STEPHEN. But I fear my father, for he is in a rage,\n",
            "    And hath no money enough. The wine is cold, the meat cold,\n",
            "    And the dishes cold, and the stomach cold.\n",
            "  MENENIUS. I am sick of sickness. No! I'll drink no matter.\n",
            "    My father is dead. I must die. What want a heart in a\n",
            "    stomach?\n",
            "  MENENIUS. My wife.\n",
            "  STEPHEN. Thou shalt not die.\n",
            "  MENENIUS. No; thou shalt not die. I cannot stay a word with him\n",
            "    till his health shall be well enough ta'en by me. And\n",
            "    that is my only wish. To take my place. But I'll drink nothing in\n",
            "    the town. Come, gentlemen. Will you make haste, sir?\n",
            "  STEPHEN. Nay, I'll be ready by five o' the clock.\n",
            "  MENENIUS. Shall we have some news with a man that we\n",
            "    talk nothing of?\n",
            "  MENENIUS. O, no, sir.\n",
            "  STEPHEN. O, 'twould be; for he had a son that\n",
            "    hath no heir to his father's place, and\n",
            "    Is but a bastard, if you say I hear so.\n",
            "  MENENIUS. Good morrow; see you your son?\n",
            "  THURIO. I'll be your attendant, though he be call'd Sir\n",
            "  STEPHEN. Why am I so call'd? I never heard his father be so\n",
            "    temperate.                                            [Aside]\n",
            "  MENENIUS. And he should be here; for what if he be not? I\n",
            "    Will drink no more.                           [They sit down]\n",
            "  MENENIUS. You will serve him. You shall serve him.\n",
            "  STEPHEN.              [They sit down and speak]\n",
            "  MENENIUS.                 [He and MENENIUS speak]\n",
            "  MENENIUS.                            [He and MENENIUS speak]\n",
            "  MENENIUS. You speak well.\n",
            "  MENENIUS. I'll drink none with him.\n",
            "  MENENIUS.                   Exeunt MENENIUS and MENENIUS,\n",
            "  MENENIUS. Well said. You did well so far,\n",
            "    Though you and I have now a head and a brain,\n",
            "    And that you have well received your father's care;\n",
            "    That he's very fond of music and loves not so much\n",
            "    As to tell you that, even now, no more\n",
            "    But I will hear him speak more music,\n",
            "    And there will I put his music in his mouth\n",
            "    Till I give him a goodly rest.\n",
            "  MENENIUS. And good rest to\n",
            "\n",
            "[610 | 1516.36] loss=2.17 avg=2.60\n",
            "[620 | 1540.50] loss=2.29 avg=2.59\n",
            "[630 | 1564.75] loss=2.24 avg=2.58\n",
            "[640 | 1589.13] loss=2.61 avg=2.58\n",
            "[650 | 1613.48] loss=2.48 avg=2.58\n",
            "[660 | 1637.76] loss=2.41 avg=2.58\n",
            "[670 | 1662.01] loss=2.51 avg=2.58\n",
            "[680 | 1686.23] loss=2.31 avg=2.57\n",
            "[690 | 1710.48] loss=2.70 avg=2.57\n",
            "[700 | 1734.65] loss=2.32 avg=2.57\n",
            "[710 | 1758.87] loss=2.47 avg=2.57\n",
            "[720 | 1783.01] loss=2.41 avg=2.56\n",
            "[730 | 1807.17] loss=1.98 avg=2.55\n",
            "[740 | 1831.40] loss=2.25 avg=2.55\n",
            "[750 | 1855.67] loss=2.52 avg=2.55\n",
            "[760 | 1879.96] loss=2.47 avg=2.54\n",
            "[770 | 1904.27] loss=2.19 avg=2.54\n",
            "[780 | 1928.60] loss=2.42 avg=2.54\n",
            "[790 | 1952.90] loss=2.39 avg=2.53\n",
            "[800 | 1977.23] loss=2.37 avg=2.53\n",
            "======== SAMPLE 1 ========\n",
            " he is no match with his master's will;\n",
            "    The best of it is he did deserve not,\n",
            "    And yet his love to her makes this false love,  \n",
            "    Even now when he sees her lovingly touch'd;\n",
            "    And yet, I think, with such a poor love\n",
            "    The devil would have thrust her from his love to him,\n",
            "    Which in love did well make her wedlock.\n",
            "  LEWIS. And his will is in her that will to him lose,\n",
            "    And so she should love him for her own sake.\n",
            "    Thus love is the end of love-\n",
            "  PETER. O, and such a love then is in his heart\n",
            "    As love doth now on mine eyes to see!\n",
            "  LEWIS. I do not protest against my love.\n",
            "    But he that loves me that did so much love her,\n",
            "    By now is her husband to me, and I'll stay;\n",
            "    And she that loves me that did so much love me,\n",
            "    So shall get her husband for her sake,\n",
            "    Since the best of her will, for love, is to stay.\n",
            "  PETER. No, I am not afraid to say no.\n",
            "    I am gentle, and yet am my master's wife;\n",
            "    And yet she's mine wife and mine, and that's not very courteous.\n",
            "  LEWIS. But she is no friend to him now.  \n",
            "  PETER. Well.\n",
            "    O, this is such a husband as you, Lewis, that love her,\n",
            "    And is as good a lover as her are.\n",
            "    How should it be said I love thee, if she be mad?\n",
            "    If love be but a vice, then by some chance\n",
            "    We may find her out, or she out, if her eyes have eyes\n",
            "    Too wide for such signs of love. But she's a most fair woman\n",
            "    And I, if I love thee, I shall make no argument\n",
            "    But that thou art virtuous. So may she, to thy husband,\n",
            "    Will she so.\n",
            "  LEWIS. But I shall not be able to keep up thine eyes;\n",
            "    Nay, it shall be more to my taste in her\n",
            "    Whiles she's awake that my eyes can see thee.\n",
            "  PETER. Nor I, sir; nor she, nor she, nor she;  \n",
            "    Nor I, unless it be some strange dream,\n",
            "    Such a woman as thou shalt hear say!\n",
            "  LEWIS. Nay, she'll be so for a husband too;\n",
            "    For she'll not hold him to be a fool.  \n",
            "  PETER. Nor I, in this respect, her.\n",
            "  LEWIS. No, not a fool; for she'll not hold him\n",
            "    To be a beggar and speak to beggars all day.\n",
            "  PETER. I have known of this woman, when she would,\n",
            "    As she speaks, and speaks in such a good voice,\n",
            "    To make such beggars laugh.\n",
            "  LEWIS. Why, then, marry, I say, thou art not mad.\n",
            "  PETER. Not to be mad: for I would not hold her to be a fool.\n",
            "  LEWIS. I know not the wit of her; but I do perceive her wit,\n",
            "    Upon her being awake she does appear to me,\n",
            "    As if she would tell you.\n",
            "  PETER. No, not of this shape.\n",
            "  LEWIS. Not I:  \n",
            "    Myself alone know'st she is not so;\n",
            "    But, indeed, she would say she lov'd you that did laugh.\n",
            "  PETER. I'll prove a fool, and teach my wife my wit;\n",
            "    And, as I say, I'll be mad at her as she is at me.\n",
            "  LEWIS. I am much distressed for my wife's death;\n",
            "    My lord here does hear me and his sister,\n",
            "    And speaks his mind, as before, of such a kind,\n",
            "    That nothing so much is know to her.\n",
            "    But what I can tell her, truly, I swear;\n",
            "    If I were alive now to come this day,\n",
            "    I could tell her of my love, and say so.\n",
            "  PETER. And so shall I when I see her play\n",
            "\n",
            "[810 | 2012.16] loss=2.09 avg=2.52\n",
            "[820 | 2036.34] loss=2.57 avg=2.52\n",
            "[830 | 2060.64] loss=2.33 avg=2.52\n",
            "[840 | 2085.06] loss=2.45 avg=2.52\n",
            "[850 | 2109.34] loss=2.55 avg=2.52\n",
            "[860 | 2133.52] loss=2.30 avg=2.52\n",
            "[870 | 2157.75] loss=2.47 avg=2.51\n",
            "[880 | 2182.01] loss=2.33 avg=2.51\n",
            "[890 | 2206.29] loss=2.34 avg=2.51\n",
            "[900 | 2230.59] loss=2.56 avg=2.51\n",
            "[910 | 2254.92] loss=2.24 avg=2.50\n",
            "[920 | 2279.25] loss=2.10 avg=2.50\n",
            "[930 | 2303.57] loss=2.59 avg=2.50\n",
            "[940 | 2327.89] loss=2.43 avg=2.50\n",
            "[950 | 2352.15] loss=2.54 avg=2.50\n",
            "[960 | 2376.41] loss=2.19 avg=2.49\n",
            "[970 | 2400.64] loss=2.00 avg=2.49\n",
            "[980 | 2424.98] loss=2.33 avg=2.48\n",
            "[990 | 2449.28] loss=2.32 avg=2.48\n",
            "[1000 | 2473.57] loss=2.54 avg=2.48\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K",
        "colab_type": "text"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd",
        "colab_type": "text"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "d59f9fa7-9715-49ed-a3ae-996fc756b37e"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "outputId": "11f19768-a7c5-49c7-e9a1-cc4862e32cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                         Exit ARVIRAGUS\n",
            "    You are nothing like her that thought on her.\n",
            "    But what else?\n",
            "    You were a better creature if you had\n",
            "    Had rather have been a man than a woman.\n",
            "    You were more like a child than a man,\n",
            "    Than had been your father: 'Tis strange, I know\n",
            "    That women are children of men.\n",
            "    Your mother, you, and you are children of women.\n",
            "    You were married, were you not?  \n",
            "    Why, how else?\n",
            "  QUEEN KATHARINE. You were not as old as I,\n",
            "    But as old as your father was,\n",
            "    And as old as he was in his age.\n",
            "    But what else?\n",
            "  ARVIRAGUS. You were young and young in your age.\n",
            "  QUEEN KATHARINE. And so old as your father was,\n",
            "    That being no man, being a woman,\n",
            "    Whose age was not yet in your age,\n",
            "    Were not the age of your father.\n",
            "  QUEEN KATHARINE. But I say all age is so.\n",
            "    Therefore you were not as old as me as yours;\n",
            "    And so, being no man, being a woman,\n",
            "    Being old, were you no woman.\n",
            "    I am not a woman, nor am I old as yours;\n",
            "    Nor am I not of a child, by being old.\n",
            "    Therefore it is your age that is in mine age.  \n",
            "  QUEEN KATHARINE. You are too old a man and too young a woman.\n",
            "  QUEEN KATHARINE. And so am I as old as you.\n",
            "    And so am I as young as you.\n",
            "    O, I am mad as you and mad as you!\n",
            "    And so am I mad as you, and so mad as you.\n",
            "    Your age, your age, your age, your age!\n",
            "    Why, this is the world's oldest argument.\n",
            "    You are old as you, and so are you.\n",
            "    Your age, the age of your age, is the age\n",
            "    Of your age; and so is yours, the age of yours.\n",
            "    Therefore 'tis age, and so 'tis old.\n",
            "    Your age, your age, your age, your age!\n",
            "    And so 'tis, and so 'tis, and so 'tis.\n",
            "                                            Exeunt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\n",
            "SHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\n",
            "PROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\n",
            "WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
            "DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\n",
            "PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\n",
            "COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\n",
            "SERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ACT II. SCENE I.\n",
            "Rome. Before the palace\n",
            "\n",
            "Enter MENENIUS, MENECRATES, and attendants\n",
            "\n",
            "  MENENIUS. Thus, when I am not angry, I am just;\n",
            "    I am not empty of anger.\n",
            "    O, what a bloody and bloody act, what a\n",
            "    bloody deed it is to be a man!\n",
            "    Caius Ligarius, we are men, and we are sons of men.\n",
            "    Omen, Caius Ligarius, we are some of the sons of\n",
            "    Rome, and we are all the sons of Rome.\n",
            "  MENENIUS. True, and made the Romans lords of Rome.\n",
            "  MENENIUS. You are such,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab_type": "code",
        "outputId": "e787f11b-2c4c-45eb-c30f-fe6810199ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LORD. I'll give thee three times much\n",
            "    To be gracious, and give thee one great thanks;\n",
            "    For thou hast done me right.\n",
            "    The Prince, and thy brother, are come\n",
            "    And have made me a gracious Prince;\n",
            "    But, since thou hast done me wrong,\n",
            "    I'll give thee away; for I will not\n",
            "    Give away the Prince to th' undeserving\n",
            "    Of my love, that art so much in pity.\n",
            "    Now, good Prince, will I be King again?\n",
            "    Give me thy hand; for, if I live,\n",
            "    The Duke, living, shall be my eldest son.\n",
            "    Thus I go, and do my best to win him  \n",
            "    As I do to win my brother.\n",
            "    Speak, good Prince; speak no more of me.\n",
            "    Let me not bid thee thank me for it;\n",
            "    Tell me, Prince, if thou wilt be King again,\n",
            "    What thou wilt to be King of England;\n",
            " \n",
            "====================\n",
            "LORD. Pray you, my lord, what's this?\n",
            "    No more than a tabor or a pile of hay\n",
            "    Will make me beggar.\n",
            "  SECOND LORD. You may say that, if he were a man,\n",
            "    He would fetch you.\n",
            "  FIRST LORD. A kind of a man,\n",
            "    A kind of gentleman,\n",
            "    A kind of soldier,\n",
            "    A kind of soldier, and a kind of man\n",
            "    All at once, being all at once.\n",
            "  SECOND LORD. You may say he is a man;\n",
            "    It will make you laugh.\n",
            "  FIRST LORD. A fool, a fool,\n",
            "    A fool, another fool, another fool.\n",
            "  SECOND LORD. He is a gentleman.\n",
            "  FIRST LORD. I am a gentleman.\n",
            "  SECOND LORD. A gentleman of a gentleman.\n",
            "  SECOND LORD. A gentleman of a gentleman.\n",
            "  FIRST LORD. A gentleman of a gentleman.\n",
            "  SECOND LORD. A gentleman of a gentleman.\n",
            "              \n",
            "====================\n",
            "LORD. Thou art here.\n",
            "    I will answer thee on the ground.\n",
            "    O, what is thy master's wrong?\n",
            "    Is all his master's company here?\n",
            "    I will not be answer'd; and I say thy master\n",
            "    Hath abused me.\n",
            "  DUCHESS. O, good my lord,\n",
            "    So much for this! Please you, sir,\n",
            "    Let me have no more discourse with thee.                              Exeunt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\n",
            "SHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\n",
            "PROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\n",
            "WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
            "DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\n",
            "====================\n",
            "LORD. My lord, I cannot help it;\n",
            "    I have a very stomach for laughter.\n",
            "    The pastime and entertainment of my soul\n",
            "    Thy fair eye doth give me, and giving it thee,\n",
            "    Thou shalt be my choler and my bedfellow.\n",
            "    I do not disdain it to think it a toy,\n",
            "    Nor will't need to entertain it with my mind;\n",
            "    I'll be so much entertain'd with it that it cease,\n",
            "    Not being a toy. If it live, so be it.\n",
            "    I say, though it live, it never shall be so,\n",
            "    But must be a toy. I will not be merry,  \n",
            "    Nor will not be merry; but-\n",
            "    I say, though it live, it never shall be so,\n",
            "    But must be a toy, and must be merry.\n",
            "    If it live, so be it.\n",
            "  SHERIFF. I will not be merry, nor will not be merry;\n",
            "    Nor must I be merry.\n",
            "\n",
            "====================\n",
            "LORD. 'Tis not his.\n",
            "    I doubt it not, but he, who looks pale, prays\n",
            "    'Hold his tongue, and leer.-Why, what say you to me?\n",
            "    What say you to me, father?\n",
            "    Or me, my brother?'\n",
            "    Which, by the miracle of this world, in my language,\n",
            "    I pray you.\n",
            "  CHIEF JUSTICE. Well, I will be sworn.\n",
            "    His answer, by this light, is, 'I am his father.'\n",
            "    Therefore, let him have no more answer.\n",
            "    I pray you, having sworn it, now do me shame,\n",
            "    And with a dangerous oath to go with him.\n",
            "    Your brother's answer, which I know is false,\n",
            "    It stands as truth against my brother's answer,  \n",
            "    If ever his answer shall be proved.\n",
            "    Look, my brother's answer! What say you to it?\n",
            "    Your brother's answer? Let it be as true.\n",
            "    Now\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2",
        "colab_type": "text"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M \"large\" model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab_type": "code",
        "outputId": "10ad44a3-a626-4f6d-a0b4-3c36ede1f0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 465Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 108Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 739Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:11, 259Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 420Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 201Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 186Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab_type": "code",
        "outputId": "159765df-843e-4936-b91c-5aeac2632b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab_type": "code",
        "outputId": "8813af4f-a687-4ae1-84ed-b3656a274ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:32: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "The secret of life is not to make a big deal of it. It's not to try to impress the world. It's to just be. And it's to just be. It's to be.\n",
            "\n",
            "When you think about it, it's very simple. Life is about being. And that's how we are all living it. We are all living it in the moment.\n",
            "\n",
            "So when I look at this, and I see this picture of my child, and I think about how amazing and beautiful\n",
            "====================\n",
            "The secret of life is in the structure of the cells, and the complexity of the way they function is the result of their DNA and RNA.\n",
            "\n",
            "We live in an environment that is very complex, and the complexity of life is based on a very simple system: DNA and RNA.\n",
            "\n",
            "The human genome is the most complex thing in the universe.\n",
            "\n",
            "The human genome is the most complex thing in the universe.\n",
            "\n",
            "The human genome is the most complex thing in the universe.\n",
            "\n",
            "The human genome\n",
            "====================\n",
            "The secret of life is in the presence of a large enough number of people.\"\n",
            "\n",
            "He goes on to say that \"in a sense the universe is a giant, open-ended game\" and that the \"only way to win it is to become more and more and more like yourself.\"\n",
            "\n",
            "In other words, the only way to beat death is to be as like yourself as possible.\n",
            "\n",
            "What's the secret of life?\n",
            "\n",
            "There are no secrets. But there are many ways to achieve a life\n",
            "====================\n",
            "The secret of life is not in the stars. It is in the human heart. -George Bernard Shaw\n",
            "\n",
            "The ancient Greeks called it the soul, the heart, or the brain. The Greeks believed that the soul of the human being was the center of our being. It was the center of our existence. It was the source of all that we were and all that we would become. The soul was the center of all that we were and all that we would become. The soul of the human being was the source\n",
            "====================\n",
            "The secret of life is the ability to change, and change is the key to life.\n",
            "\n",
            "The secret of life is the ability to change, and change is the key to life.\n",
            "\n",
            "The secret of life is the ability to change, and change is the key to life.\n",
            "\n",
            "The secret of life is the ability to change, and change is the key to life.\n",
            "\n",
            "The secret of life is the ability to change, and change is the key to life.\n",
            "\n",
            "The secret of life is\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E",
        "colab_type": "text"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}